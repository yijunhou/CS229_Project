{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNdKsLfF0CbasHlCAhw29oH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yijunhou/CS229_Project/blob/main/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFhzNEW_Sq6O",
        "outputId": "b9b74bba-949f-4ec7-a80d-b85d721ad0dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyHwH-c1TQ8u"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muGe4aNgS8Ht"
      },
      "source": [
        "train_data = np.load('/content/gdrive/My Drive/CS229/project/Data/musicnet.npz', encoding='bytes',allow_pickle=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk_7H0xMTljT"
      },
      "source": [
        "composer_lookup = {\"Beethoven\":0,\"Schubert\":1,\"Brahms\":2,\"Mozart\":3,\"Bach\":4,\"Dvorak\":5,\"Cambini\":6,\"Faure\":7,\"Ravel\":8,\"Haydn\":9}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5y4ksf2AVteO",
        "outputId": "044f0d53-a641-4288-8fa8-d5bdec7fea30"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/CS229/project/Data/data_file.csv')\n",
        "df"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>key_id</th>\n",
              "      <th>piece_id</th>\n",
              "      <th>composer</th>\n",
              "      <th>composer_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1788</td>\n",
              "      <td>1</td>\n",
              "      <td>Mozart</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1788</td>\n",
              "      <td>2</td>\n",
              "      <td>Mozart</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1788</td>\n",
              "      <td>3</td>\n",
              "      <td>Mozart</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1788</td>\n",
              "      <td>4</td>\n",
              "      <td>Mozart</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1788</td>\n",
              "      <td>5</td>\n",
              "      <td>Mozart</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12121</th>\n",
              "      <td>12121</td>\n",
              "      <td>12121</td>\n",
              "      <td>1765</td>\n",
              "      <td>63</td>\n",
              "      <td>Schubert</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12122</th>\n",
              "      <td>12122</td>\n",
              "      <td>12122</td>\n",
              "      <td>1765</td>\n",
              "      <td>64</td>\n",
              "      <td>Schubert</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12123</th>\n",
              "      <td>12123</td>\n",
              "      <td>12123</td>\n",
              "      <td>1765</td>\n",
              "      <td>65</td>\n",
              "      <td>Schubert</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12124</th>\n",
              "      <td>12124</td>\n",
              "      <td>12124</td>\n",
              "      <td>1765</td>\n",
              "      <td>66</td>\n",
              "      <td>Schubert</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12125</th>\n",
              "      <td>12125</td>\n",
              "      <td>12125</td>\n",
              "      <td>1765</td>\n",
              "      <td>67</td>\n",
              "      <td>Schubert</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12126 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0     ID  key_id  piece_id  composer  composer_id\n",
              "0               0      0    1788         1    Mozart            3\n",
              "1               1      1    1788         2    Mozart            3\n",
              "2               2      2    1788         3    Mozart            3\n",
              "3               3      3    1788         4    Mozart            3\n",
              "4               4      4    1788         5    Mozart            3\n",
              "...           ...    ...     ...       ...       ...          ...\n",
              "12121       12121  12121    1765        63  Schubert            1\n",
              "12122       12122  12122    1765        64  Schubert            1\n",
              "12123       12123  12123    1765        65  Schubert            1\n",
              "12124       12124  12124    1765        66  Schubert            1\n",
              "12125       12125  12125    1765        67  Schubert            1\n",
              "\n",
              "[12126 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZIhWn-3YPJM"
      },
      "source": [
        "fs = 44100\n",
        "chunk_size = 10\n",
        "sr = 10\n",
        "n_classes = 10"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59JWnprVV2UA",
        "outputId": "21b1b512-204a-4b36-a359-62bf580ea354"
      },
      "source": [
        "i= 0\n",
        "X, y = [], []\n",
        "for data in tqdm(df.iterrows(),  desc='Progress'):\n",
        "    key = str(data[1]['key_id'])\n",
        "    piece = data[1]['piece_id'] -1\n",
        "    chunks = int((len(train_data[key][0]))/fs/chunk_size)\n",
        "    a = np.array_split(train_data[key][0], chunks)[piece][::sr]\n",
        "    # mfcc_ = librosa.feature.mfcc(a, sr=fs, n_mfcc=40)\n",
        "    X = np.append(X, a[0:400])\n",
        "    del(a)\n",
        "    y.append(data[1]['composer_id'])\n",
        "    if i == 5000:\n",
        "      break\n",
        "    else:\n",
        "      i += 1\n",
        "    '''\n",
        "    elif i % 10 == 0 and i > 0:\n",
        "      X = np.array(X)\n",
        "      np.save('batch_1.npy', X, allow_pickle = True, fix_imports=True)\n",
        "      del(X)\n",
        "      X = np.load('batch_1.npy', allow_pickle= True)\n",
        "      i += 1\n",
        "    '''\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 5000it [3:08:23,  2.26s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdPLZunvH1pl"
      },
      "source": [
        "np.save('/content/gdrive/My Drive/CS229/project/Data/transformer_x.npy', X)\n",
        "np.save('/content/gdrive/My Drive/CS229/project/Data/transformer_y.npy', y)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrvWJt4cH12p"
      },
      "source": [
        "X = np.load('/content/gdrive/My Drive/CS229/project/Data/transformer_x.npy')\n",
        "y = np.load('/content/gdrive/My Drive/CS229/project/Data/transformer_y.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVducXJzH15a",
        "outputId": "f8991099-c4d2-4705-f420-8562def0c2c2"
      },
      "source": [
        "print(Counter(y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 2345, 2: 777, 1: 614, 3: 542, 4: 407, 8: 134, 6: 81, 5: 79, 9: 22})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E_c2if7H18C",
        "outputId": "ff6855ed-716d-4d4b-9fd8-14a4c28d9099"
      },
      "source": [
        "X_ = np.array(X)\n",
        "print(X_.shape)\n",
        "X_ = X_.reshape((5001, -1, 1))\n",
        "y_ = tf.keras.utils.to_categorical(y , num_classes= n_classes)\n",
        "print(X_.shape, y_.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000400,)\n",
            "(5001, 400, 1) (5001, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIY8907fI14b",
        "outputId": "810a44e3-006d-4c03-bca0-d1151de777ee"
      },
      "source": [
        "x_train, x_rest, y_train, y_rest = train_test_split(X_, y_, test_size = 0.2, \n",
        "                                                   random_state = 42, stratify = y_)\n",
        "x_validation, x_test, y_validation, y_test = train_test_split(x_rest, y_rest, test_size = 0.5, \n",
        "                                                   random_state = 42, stratify = y_rest)\n",
        "print(x_train.shape, x_validation.shape, x_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 400, 1) (500, 400, 1) (501, 400, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkO9C5aOI17x"
      },
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXJOwulFI4Gc"
      },
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2n1PimqI4JL",
        "outputId": "44b32230-4d8d-4b44-8d29-8a4f4bb07503"
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    #validation_split=0.2,\n",
        "    validation_data = (x_validation, y_validation),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 400, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 400, 1)      2           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 400, 1)      7169        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 400, 1)       0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 400, 1)      0           ['dropout[0][0]',                \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 400, 4)       8           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 400, 4)       0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 400, 1)       5           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 400, 1)      0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 400, 1)      7169        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 400, 1)       0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 400, 1)      0           ['dropout_2[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 400, 4)       8           ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 400, 4)       0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 400, 1)       5           ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 400, 1)      0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 400, 1)      7169        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 400, 1)       0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 400, 1)      0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 400, 4)       8           ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 400, 4)       0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 400, 1)       5           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 400, 1)      0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 400, 1)      7169        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 400, 1)       0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 400, 1)      0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 400, 1)      2           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 400, 4)       8           ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 400, 4)       0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 400, 1)       5           ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 400, 1)      0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 400)         0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          51328       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           1290        ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 81,362\n",
            "Trainable params: 81,362\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 477s 8s/step - loss: 1.9866 - acc: 0.3270 - val_loss: 1.6602 - val_acc: 0.4660\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 469s 7s/step - loss: 1.7071 - acc: 0.4568 - val_loss: 1.6527 - val_acc: 0.4660\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 483s 8s/step - loss: 1.6899 - acc: 0.4568 - val_loss: 1.6417 - val_acc: 0.4660\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 478s 8s/step - loss: 1.6817 - acc: 0.4633 - val_loss: 1.6255 - val_acc: 0.4660\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 479s 8s/step - loss: 1.6640 - acc: 0.4655 - val_loss: 1.6191 - val_acc: 0.4680\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 480s 8s/step - loss: 1.6707 - acc: 0.4645 - val_loss: 1.6245 - val_acc: 0.4680\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 479s 8s/step - loss: 1.6645 - acc: 0.4660 - val_loss: 1.6175 - val_acc: 0.4680\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 475s 8s/step - loss: 1.6517 - acc: 0.4675 - val_loss: 1.6154 - val_acc: 0.4680\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 474s 8s/step - loss: 1.6531 - acc: 0.4655 - val_loss: 1.6199 - val_acc: 0.4680\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 468s 7s/step - loss: 1.6512 - acc: 0.4680 - val_loss: 1.6176 - val_acc: 0.4680\n",
            "16/16 [==============================] - 20s 1s/step - loss: 1.6050 - acc: 0.4691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6049537658691406, 0.46906188130378723]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81WV0ROYH1-i",
        "outputId": "dca27ab1-1958-4935-fdfa-5e70dc5ed40a"
      },
      "source": [
        "Counter(np.argmax(model.predict(x_train), axis=1))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3999, 2: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4PPLSn7H2BD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOZx-e8TH2DR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ASxdd0OH2Fi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}